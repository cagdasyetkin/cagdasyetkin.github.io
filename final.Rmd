---

---

<b>2018.27.02 </b>
<style> body { text-align: justify} </style>

###I analyze a large dataset of commercial records produced by Assyrian merchants in the 19th Century BCE...

This is a text mining project for Unstructured Text Data Course I take from Business Analytics department of Central European University. I don't have any history, archeology or any social science background other than watching Indiana Jones and playing Lara Croft's Tomb Rider. On the other hand, I did some google search to give you the context and placed them here.

The aim of the project is to make sense of some text which I have no idea about. However, If you give feedback I will be happy to update the post.

This is about an acient language from the Bronze Age, meaning like 4000 years ago.

[this is how the language sounded like...](https://soundcloud.com/user444756202/the-epic-of-gilgames-standard-version-tablet-xi-lines-1-163-read-by-karl-hecker "from Gilgamesh")


<b>2018.01.03 </b>

###And this is how it looked like:

<img src="final_files/sample.png" alt="sample" height="200" width="300">


<b>2018.02.03 </b>


###Some smart people decrypted these languages. For example

nu ninda en e-iz-za-te-ni </n>
<b>wa-a-tar</b>-ma e-ku-ut-te-ni

Translation:

"Now you will eat bread and drink water"

wa-a-tar means water. ninda means bread. Quite familiar isn't it?


###Our data looks like this:

This is a txt file.


<img src="final_files/sample2.png" alt="data" height="300" width="500">


But how did I get here? It started with a tweet by Gabor Bekes:


<img src="final_files/tweetgabor.PNG" alt="data" height="300" width="500">



I contacted the authors of this academic paper from the University of Virginia. They were so kind and provided me these text files:


<img src="final_files/kerememail.PNG" alt="data" height="300" width="500">




Archeologists have escavated these tablets during the past 200 years.

###An escavated tablet looks like this:

<img src="final_files/sample3.png" alt="tablet" height="200" width="200">



###These people lived 4000 years ago in the Middle East and the Asia Minor

<b>2018.03.05 </b>

We will start by loading our documents. We have many unwanted words and phrases. Some simple regular expressions will help us.

```{r, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
```

```{r, message=FALSE, warning=FALSE}
#we have a collection of 4 documents
library(dplyr)
oare1 <- readLines("OARE_01.txt") %>%
  data_frame(file = 'OARE_1') %>%
  rename('word' = '.') 

oare2 <- readLines("OARE_02.txt") %>%
  data_frame(file = 'OARE_2') %>%
  rename('word' = '.') 

oare3 <- readLines("OARE_03.txt") %>%
  data_frame(file = 'OARE_3') %>%
  rename('word' = '.') 

oare4 <- readLines("OARE_04.txt") %>%
  data_frame(file = 'OARE_4') %>%
  rename('word' = '.') 

txt <- bind_rows(list(oare1, oare2, oare3, oare4)) 
colnames(txt) <- c("text", "title")

#see the lines give the information regarding the Creator of the record
head(txt[grep('^Creator', txt$text),], 3)

#removing them
txt <- txt %>%
  anti_join(txt[grep('^Creator', txt$text),])
```


This is one way of cleaning such unwanted words... We can create a list of them, match and then anti_join easily.

<b>2018.03.06 </b>

toMatch is a vector of unwanted character strings with some regular expressions just like above example.
We remove them from our text below.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
toMatch <- c("^Primary", "^Translation", "^logosyllabic", "^Epistolary", "^Formul", "^Creator", 
             "^Editor", "^List", "^Introductory","^Publication", "^Physical" ,"^Chantre", "^Broken",
             
             "^German", "^French ", "^Topic", "^“Kuzuoğlu", "^Body", "^Kayseri ",
             "^Periods", "^Kültepe", "^Karaduman", "^Kültepe", "Adana","^Seizure", 
             "^Bılgıç", "^First Topic", "^AnOr", "^Garelli", "^Liège", "^Prag",
             "^Ulshöfer", "^Burrill", "^Burton", "^Cole ", "^Eilsberger", "^hellbraunes",
             "^Stratford", "^Rendell", "^Schaeffer", "^Struwe", "^Larsen",
             
             "^AAA", "^A ", "^Ac.", "^ATHE", "^BIN", "^AKT", "^AO", "OARE", "^     ", "^KTB ",
             "^C ", "^CCT", "^CKAS", "^CTMMA", "^EL ", "^H.K. ", "^ICK ", "^JCS ", "^kt ",
             "^KTH ", "^KTS ", "^KUG ", "^¢", "^LB ", "^OIP ", "^POAT ", "^RA ", "^TC ", "^TMH ",
             "^TTC ", "^VS ", "^YBC ")

```

```{r, message=FALSE, warning=FALSE, fig.align = 'center'}
library(pander)
matches <- unique (grep(paste(toMatch,collapse="|"), 
                        txt$text, value=TRUE))

#removing them
txt <- txt %>%
  anti_join(data.frame(text = matches)) 

original_text <- txt # keep an untouched copy

#take a look at one commercial record now
pander(txt[149:150, 1])


```

Here we are reading a business letter from a guy called Abela to Idnaya. Just a quick look makes it clear that these people were not savages at all. Freight charges, clearing a debt on behalf of another entity and stamps (seals) are all in place. 

The paragraph is almost clean. Next, we need to remove the numbers.


<b>2018.03.07 </b>

```{r, message=FALSE, warning=FALSE}
# Remove numbers using removeNumber function from tm library
library(tm)

txt$text <- txt$text %>%
  removeNumbers() %>%
  removePunctuation() %>% #in fact unnest_tokens function is handling this
  stripWhitespace()

```

Now let's have a quick look at the word frequencies

```{r, message=FALSE, fig.width=7,fig.height=4}
library(tidytext)
library(ggplot2)
library(ggthemes)

txt %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>%
  filter(n > 150) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) + geom_col() + xlab(NULL) + coord_flip() +
  ggtitle("Word Frequency")
  
```

It looks like these people were sending and receiving textiles, tin and copper. Transportation was mostly depending on donkeys and the payments were in silvers most of the time. The units of measurement (like the weight) were shekels, minas and talents. Example: Abele sends 5 talents of gold to Ibalaya for 200 shekels of silver, on behalf of Iddin-Istar.


<b>2018.03.08 </b>

Looking at the frequency plot again, what does **pusuken** mean? It is repeating more than 500 times...

```{r}
library(stringr)
head(original_text[str_detect(original_text$text, "Pusu-ken"), 1], 5)
```

A family business! It turns out Pusuken was the most famous businessman. Probably he was the leader of a powerful family controlling most of the trade happening in the region. His sons were handling the transactions. Assurnada and Assurmalik are the other two notable tradesmen coming out from the frequency table.

Another frequent word is 'son'. Let's find out why.

```{r}
tail(original_text[str_detect(original_text$text, "son"), 1], 5)
```

son of Assurnada, son of Inahili, son of Iddin... Of course, these are family names. That's why it repeats a lot.

<b>2018.03.10 </b>

Now we have a fairly good understanding of the most frequent words. Let's get a big picture of the ancient cities mentioned in our text. 

Ancient city names are easily available online. We will join them with our text. Our objective is to see how many times these cities are mentioned in our text and visualize them.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
#Information from archeological findings
known_cities <- data.frame(cityName = c("hanaknak", "hattus", "hurama", "kanesh", "karahna", 
                                        "qattara", "salatuwar", "samuha", "tapaggas", 
                                        "timelkiya", "ulama", "unipsum", "wahsusana", "zimishuna"), 
                  type = 'known',
                  modern_name = c("Cankiri", "Bogazkoy", "Kusura", "Kultepe", "Sulusaray", 
                                  "Tell al-Rimah", "Mersin", "Kayapinar", "MasatHoyuk", "Telmessos",
                                  "Silifke", "Tünip", "Cyprus", "Samsun"),
                  latitude = c(40.6002, 40.018499926, 38.360937, 38.851165, 39.986138,
                               36.152551, 36.816874, 39.319128, 40.0854, 36.618181,
                               36.318340, 35.1725, 35.103410, 41.280517),
                  longitude = c(33.6162, 34.60916423, 30.230104, 35.635486, 36.093526,
                                42.265761, 34.687688, 36.309621, 35.4544, 29.117308,
                                33.869491, 36.2359, 33.338150, 36.327963)
                  )  
#lost city coordinates are estimates from the article
lost_cities <- data.frame(cityName = c("durhumit", "hahhum", "kuburnat", "mamma", "ninassa",
                                       "purushaddum", "sinahuttum", "suppiluliya", "tuhpiya",
                                       "washaniya", "zalpa"), 
                 type = 'lost',
                 latitude = c(40.725, 38.126, 39.748, 38.053, 38.714, 40.308, 40.056, 40.062,
                              39.787, 39.189, 37.704),
                 longitude = c(35.178, 37.776, 35.919, 36.301, 34.256, 33.379, 34.933, 34.683,
                               35.274, 34.221, 37.347))

cities <- bind_rows(known_cities, lost_cities)

```


```{r}
library(tidyr)

cities <- cities %>%
  left_join(original_text %>%
                unnest_tokens(word, text) %>%
                filter(word %in% tolower(cities$cityName)) %>%
                count(word, sort = TRUE) %>%
                rename(cityName = word),
            
            by = 'cityName')

cities$n <- replace_na(cities$n, 0)
```

```{r}
cities %>%
  select(cityName, latitude, longitude, n) %>%
  rename(Occurance_In_Text = n) %>%
  arrange(desc(Occurance_In_Text)) %>%
  head() %>%
  pander::pander()

#cities to plot
cities_in_text <- cities %>%
  filter(n > 0)
```

The city of Kanesh is our biggest hub. Probably a capital city. Our famous Pusheken family must have lived here.

```{r, message=FALSE, warning=FALSE, fig.width=7,fig.height=4}
library(ggmap)
library(ggthemes)

#setup map borders and select your map style
lat <- cities$latitude
long <- cities$longitude
bbox <- make_bbox(long,lat,f=0.5)
b <- get_map(bbox,maptype="watercolor",source="google")

#plot the cities mentioned in the text
ggmap(b) + geom_point(data = cities_in_text, 
           aes(longitude, latitude, size=n),alpha=0.2, show.legend = F) +
           scale_size_continuous(range = c(3, 10)) +
  
           labs(x = "Longitude", y = "Latitude",
           title="City Locations / Size = Occurance in Text", color = "Type") +
  
           geom_text(data = cities_in_text, aes(longitude, latitude, label = cityName), 
                     check_overlap = TRUE) + 
theme_gdocs()
```

You are looking at the Asia Minor, Mezzopotamia, the Middle East, Greece and the southeast Mediterrenean Sea. The largest islands you see are the island of Crete and Cyprus. 

The people who wrote these tablets were using the sea ports in Timelkiya, Ulama and Salatuwar. So we are talking about some complicated trade network here. Probably Pharaohs of ancient Egypt, Phonecians and Mycenaeans are all playing some role.

<b>2018.03.11 </b>

We know the most frequent words in these documents. How about the most important ones? We can try tfidf here.
```{r}
oare_words <- txt %>%
  unnest_tokens(word, text) %>%
  count(title, word, sort = TRUE) %>%
  ungroup()

total_words <- oare_words %>% 
  group_by(title) %>% 
  summarize(total = sum(n))

oare_words <- left_join(oare_words, total_words, by = 'title')
```

```{r, message=FALSE, warning=FALSE, results='hide'}
oare_stop_words <- data.frame(word = c("gkt", "sec", "oaa", "ca", "g"), lexicon = 'oare')

oare_words <- oare_words %>%
  anti_join(oare_stop_words) %>%
  bind_tf_idf(word, title, n)

oare_words %>%
  select(-total) %>%
  arrange(desc(tf_idf)) %>%
  head(10) %>%
  select(title, word, n, tf_idf)
```

```{r, fig.height=3, fig.width=6, message=FALSE}
oare_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  #group_by(title) %>% 
  top_n(5) %>% 
  #ungroup %>%
  ggplot(aes(word, tf_idf, fill = title)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  #facet_wrap(~title, ncol = 2, scales = "free") +
  coord_flip() + theme_gray()
```

We had ruling family names in the word frequency plot. They were the **Pusuken, Assurnada and Assurmalik** families. 

Now we have some other names being reported in tfidf plots. And by far, the most significant names are **Kuliya and Aliabum**. These names are more important then the powerful families according to the algorithm. They are also more important then gold, silver and the trade items. Maybe they are not mentioned that much. But they seem to play some significant role. This is really curious. Who are these people?


```{r, fig.align='center'}
head(original_text[str_detect(original_text$text, "Kuliya"), 1], 15)[4, ] %>%
  pander::pander()
```

Kuliya is a servant of Pusuken family. He delivers messages, goods and payments. He is Kuliya, son of Aliabum. Loyal servant of the sons of Pusuken. He takes the caravans from Kanesh and brings to the port of Ulama in the south. There he loads the cargo to the ships. Aliabum is his father. They call him Kuliya, son of Aliabum. This trade network can not function without him.

Can we draw the anatomy of this trade network? 

```{r, warning=FALSE, message=FALSE, fig.width=10}
library(tidyr)
library(igraph)
library(ggraph)

#create bigram
oare_bigrams <- txt %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

#separate them
bigrams_separated <- oare_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

#filter out stopwords
bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) 

#bigram counts:
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

#create a graph
bigram_graph <- bigram_counts %>%
  filter(n > 30) %>%
  graph_from_data_frame()

#plot the graph

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
set.seed(2016)
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()


```


*Kuliya wakes up early morning with the sound of black >> donkeys. They are on the way to port Ulama.*

*The main cargo is 300 kutanum >> textiles. It worths more than 10 talents >> and 50 minas >> of silver according to the tablet he is carrying with him. The letter starts with Dear >> brothers again. He doesn't understand why sons of Pusuken call these bastards brother all the time.*

*Transport >> tariff is 60 shekels >> of silver. They will report it to the colony >> office in Ulama when they arrive, with approved delivery notice. He will deliver a huge profit to the family to clear all the claims >> outstanding*

This network plot is quite informative. We see the monatery system around the **silver** and the order of scale for measurement. Talent is the biggest and probably a **refined silver** is the most valuable. Shekels should be like cents. Shekel - Minas - Silver is the strongest triangle of payment. Textile measurements are in kutanum. Strong presence of **colony office** is indicating a regulating superpower, most probably the Empire.


<b>2018.03.13 </b>

How do these letters feel like? Mostly positive or negative language? I found some online articles about Assyrian Emperors. Their texts are all about burning, killing, torturing and beheading. How about these?

```{r, warning=FALSE, message=FALSE}
#first get the tidy format
tidy_oare <- txt %>%
  group_by(title) %>%
  mutate(linenumber = row_number()) %>%
  ungroup() %>%
  unnest_tokens(word, text)
  

#build afinn bing and nrc lexicon sentiments
afinn <- tidy_oare %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(tidy_oare %>% 
                            inner_join(get_sentiments("bing")) %>%
                            mutate(method = "Bing et al."),
                          tidy_oare %>% 
                            inner_join(get_sentiments("nrc") %>% 
                                         filter(sentiment %in% c("positive", 
                                                                 "negative"))) %>%
                            mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

#plot the sentiments together
bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y") + theme_fivethirtyeight()
```

Looks like you need to be politer if you want to make some money. These are carefully written for record keeping and contain clear instructions. A few negative cases are curious. What can cause negativity in these business letters?

```{r, message=FALSE, fig.width=4, fig.height=4}
#Check the negativity using a word cloud
library(wordcloud)
library(reshape2)
tidy_oare %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 50)
```

Some things have never changed. These are still the major problems of a typical tradesman. *debts, lost - perished and broken products, delays, concerns and complaints* 

xxx




