---

---

<b>2018.27.02 </b>
<style> body { text-align: justify} </style>

###I analyze a large dataset of commercial records produced by Assyrian merchants in the 19th Century BCE...



[this is how the language sounded like...](https://soundcloud.com/user444756202/the-epic-of-gilgames-standard-version-tablet-xi-lines-1-163-read-by-karl-hecker "from Gilgamesh")


<b>2018.01.03 </b>

###And this is how it looked like:

![](sample.png)

<b>2018.02.03 </b>


###Some smart people decrypted these languages. For example

nu ninda en e-iz-za-te-ni </n>
<b>wa-a-tar</b>-ma e-ku-ut-te-ni

Translation:

"Now you will eat bread and drink water"

wa-a-tar means water. ninda means bread. Quite familiar isn't it?


###Records in our database look like this:

![](sample2.png)





###An escavated tablet looks like this:

<img src="sample3.png" alt="tablet" height="420" width="420">



###These people lived 4000 years ago. And this is where they lived:

![](sample4.jpg)

<b>2018.03.05 </b>

When we load the data, we will need to get rid of many words and phrases. Some simple regular expressions will help us. For example:

```{r, message=FALSE, warning=FALSE}
#Load the sample data
library(dplyr)
txt <- readLines("OARE_01.txt") %>%
  data_frame() %>%
  rename('word' = '.') 

#see the lines give the information regarding the Creator of the record
head(txt[grep('^Creator', txt$word),], 3)

#removing them
txt <- txt %>%
  anti_join(txt[grep('^Creator', txt$word),])
```

Using this method, we can do the cleaning





