<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}

.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Cagdas Yetkin</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="quiz.html">Quiz</a>
</li>
<li>
  <a href="final.html">Final Project</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="http://github.com/cagdasyetkin">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/cagdasyetkin">
    <span class="fa fa-twitter fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/cagdasyetkin/">
    <span class="fa fa-linkedin fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<hr />
<hr />
<b>2018.27.02 </b>
<style> body { text-align: justify} </style>
<div id="i-analyze-a-large-dataset-of-commercial-records-produced-by-assyrian-merchants-in-the-19th-century-bce" class="section level3">
<h3>I analyze a large dataset of commercial records produced by Assyrian merchants in the 19th Century BCE…</h3>
<p>This is a text mining project for Unstructured Text Data Course I take from Business Analytics department of Central European University. I don’t have any history, archeology or any social science background other than watching Indiana Jones and playing Lara Croft’s Tomb Raider. On the other hand, I did some google search to give you the context and placed them here.</p>
<p>The aim of the project is to make sense of some text which I have no idea about. However, If you give feedback I will be happy to update the post.</p>
<p>This is about an acient language from the Bronze Age, meaning like 4000 years ago.</p>
<p><a href="https://soundcloud.com/user444756202/the-epic-of-gilgames-standard-version-tablet-xi-lines-1-163-read-by-karl-hecker" title="from Gilgamesh">this is how the language sounded like…</a></p>
<p><b>2018.01.03 </b></p>
</div>
<div id="and-this-is-how-it-looked-like" class="section level3">
<h3>And this is how it looked like:</h3>
<p><img src="final_files/sample.PNG" alt="sample" height="200" width="300"></p>
<p><b>2018.02.03 </b></p>
</div>
<div id="some-smart-people-decrypted-these-languages.-for-example" class="section level3">
<h3>Some smart people decrypted these languages. For example</h3>
<p>nu ninda en e-iz-za-te-ni </n> <b>wa-a-tar</b>-ma e-ku-ut-te-ni</p>
<p>Translation:</p>
<p>“Now you will eat bread and drink water”</p>
<p>wa-a-tar means water. ninda means bread. Quite familiar isn’t it?</p>
</div>
<div id="our-data-looks-like-this" class="section level3">
<h3>Our data looks like this:</h3>
<p>This is a txt file.</p>
<p><img src="final_files/sample2.PNG" alt="data" height="300" width="500"></p>
<p>But how did I get here? It started with a tweet by Gabor Bekes:</p>
<p><img src="final_files/tweetgabor.PNG" alt="data" height="300" width="500"></p>
<p>I contacted the authors of this academic paper from the University of Virginia. They were so kind and provided me these text files:</p>
<p><img src="final_files/kerememail.PNG" alt="data" height="300" width="500"></p>
<p>Archeologists have escavated these tablets during the past 200 years.</p>
</div>
<div id="an-escavated-tablet-looks-like-this" class="section level3">
<h3>An escavated tablet looks like this:</h3>
<p><img src="final_files/sample3.png" alt="tablet" height="200" width="200"></p>
</div>
<div id="these-people-lived-4000-years-ago-in-the-middle-east-and-the-asia-minor" class="section level3">
<h3>These people lived 4000 years ago in the Middle East and the Asia Minor</h3>
<p><b>2018.03.05 </b></p>
<p>We will start by loading our documents.</p>
<pre class="r"><code>#we have a collection of 4 documents
library(dplyr)
oare1 &lt;- readLines(&quot;OARE_01.txt&quot;) %&gt;%
  data_frame(file = &#39;OARE_1&#39;) %&gt;%
  rename(&#39;word&#39; = &#39;.&#39;) 

oare2 &lt;- readLines(&quot;OARE_02.txt&quot;) %&gt;%
  data_frame(file = &#39;OARE_2&#39;) %&gt;%
  rename(&#39;word&#39; = &#39;.&#39;) 

oare3 &lt;- readLines(&quot;OARE_03.txt&quot;) %&gt;%
  data_frame(file = &#39;OARE_3&#39;) %&gt;%
  rename(&#39;word&#39; = &#39;.&#39;) 

oare4 &lt;- readLines(&quot;OARE_04.txt&quot;) %&gt;%
  data_frame(file = &#39;OARE_4&#39;) %&gt;%
  rename(&#39;word&#39; = &#39;.&#39;) 

txt &lt;- bind_rows(list(oare1, oare2, oare3, oare4)) 
colnames(txt) &lt;- c(&quot;text&quot;, &quot;title&quot;)</code></pre>
<p>How many tablets do we have? We can simply count the Creators.</p>
<pre class="r"><code>library(stringr)
str_c(&quot;We have &quot;, nrow(txt[grep(&#39;^Creator&#39;, txt$text),]), &quot; tablets&quot;) %&gt;%
  pander::pander()</code></pre>
<p>We have 609 tablets</p>
<p>We have many unwanted words and phrases. Some simple regular expressions will help us.</p>
<pre class="r"><code>#see the lines give the information regarding the Creator of the record
head(txt[grep(&#39;^Creator&#39;, txt$text),], 3)</code></pre>
<pre><code>## # A tibble: 3 x 2
##   text                                             title 
##   &lt;chr&gt;                                            &lt;chr&gt; 
## 1 Creator(s): Stratford, Edward P.                 OARE_1
## 2 Creator(s): Stratford, Edward P.                 OARE_1
## 3 &quot;Creator(s): Stratford, Edward P. (2016-12-24) &quot; OARE_1</code></pre>
<pre class="r"><code>#removing them
txt &lt;- txt %&gt;%
  anti_join(txt[grep(&#39;^Creator&#39;, txt$text),])</code></pre>
<p>This is one way of cleaning such unwanted words… We can create a list of them, match and then anti_join easily.</p>
<p><b>2018.03.06 </b></p>
<p>toMatch is a vector of unwanted character strings with some regular expressions just like above example. We remove them from our text below.</p>
<pre class="r"><code>library(pander)
matches &lt;- unique (grep(paste(toMatch,collapse=&quot;|&quot;), 
                        txt$text, value=TRUE))

#removing them
txt &lt;- txt %&gt;%
  anti_join(data.frame(text = matches)) 

original_text &lt;- txt # keep an untouched copy

#take a look at one commercial record now
pander(txt[149:150, 1])</code></pre>
<table style="width:43%;">
<colgroup>
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">4-6I entrusted 15 minas 54 shekels silver under my seal, 16 shekels its shipping charge, to Assur-samsi on behalf of Al-ili.</td>
</tr>
<tr class="even">
<td align="center">7-8There, make sure the representative of Al-ili recieves the silver and it’s shipping charge. 9-11I gave 5 1/2 minas silver of my own to Assur-samsi for purchases.</td>
</tr>
</tbody>
</table>
<p>Here we are reading a business letter from a guy called Abela to Idnaya. Just a quick look makes it clear that these people were not savages at all. Freight charges, clearing a debt on behalf of another entity and stamps (seals) are all in place.</p>
<p>The paragraph is almost clean. Next, we need to remove the numbers.</p>
<p><b>2018.03.07 </b></p>
<pre class="r"><code># Remove numbers using removeNumber function from tm library
library(tm)

txt$text &lt;- txt$text %&gt;%
  removeNumbers() %&gt;%
  removePunctuation() %&gt;%
  tolower() %&gt;% #in fact unnest_tokens function handling this
  stripWhitespace()</code></pre>
<p>Now let’s have a quick look at the word frequencies</p>
<pre class="r"><code>library(tidytext)
library(ggplot2)
library(ggthemes)

txt %&gt;%
  unnest_tokens(word, text) %&gt;%
  anti_join(stop_words) %&gt;%
  count(word, sort = TRUE) %&gt;%
  filter(n &gt; 150) %&gt;%
  mutate(word = reorder(word, n)) %&gt;%
  ggplot(aes(word, n)) + geom_col() + xlab(NULL) + coord_flip() +
  ggtitle(&quot;Word Frequency&quot;)</code></pre>
<p><img src="final_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>It looks like these people were sending and receiving textiles, tin and copper. Transportation was mostly depending on donkeys and the payments were in silvers most of the time. The units of measurement (like the weight) were shekels, minas and talents. Example: Abele sends 5 talents of gold to Ibalaya for 200 shekels of silver, on behalf of Iddin-Istar.</p>
<p><b>2018.03.08 </b></p>
<p>Looking at the frequency plot again, what does <strong>pusuken</strong> mean? It is repeating more than 500 times…</p>
<pre class="r"><code>head(original_text[str_detect(original_text$text, &quot;Pusu-ken&quot;), 1], 4) %&gt;%
  pander()</code></pre>
<table style="width:44%;">
<colgroup>
<col width="44%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1-3To Amur-Istar and Pusu-ken from Kuzallum:</td>
</tr>
<tr class="even">
<td align="center">1-2From su-hubur to Pusu-ken:</td>
</tr>
<tr class="odd">
<td align="center">1-7Zupa seized us against the sons of Pusu-ken and Zupa said to the sons of Pusu-ken, “Your father took the silver stated in my sealed tablets.</td>
</tr>
<tr class="even">
<td align="center">7-9Why is it that Suen-re’i detains me? 10-18The sons of Pusu-ken (responded): “Our father received the silver of the sealed tablet of Zupa. Release it and we will give you the matter.”</td>
</tr>
</tbody>
</table>
<p>A family business! It turns out Pusuken was the most famous businessman. Probably he was the leader of a powerful family controlling most of the trade happening in the region. His sons were handling the transactions. Assurnada and Assurmalik are the other two notable tradesmen coming out from the frequency table.</p>
<p>Another frequent word is ‘son’. Let’s find out why.</p>
<pre class="r"><code>tail(original_text[str_detect(original_text$text, &quot;son&quot;), 1], 5)[c(1, 3), ] %&gt;%
  pander()</code></pre>
<table style="width:43%;">
<colgroup>
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Iddin-Istar son of Assur-nada owes 5 5/6</td>
</tr>
<tr class="even">
<td align="center">15-18Witnesses: Burqanim son of Kakkabanim son of su-Istar son of suaya</td>
</tr>
</tbody>
</table>
<p>son of Assurnada, son of Inahili, son of Kakkabanim… Of course, these are family names. That’s why it repeats a lot.</p>
<p><b>2018.03.10 </b></p>
<p>Now we have a fairly good understanding of the most frequent words. Let’s get a big picture of the ancient cities mentioned in our text.</p>
<p>Ancient city names are easily available online. I created a dataframe called “Citites” which contain their geolocations. We will join information into this dataframe from our text. Our objective is to come up with some metric which can represent trading power of these cities, and visualize them.</p>
<pre class="r"><code>library(tidyr)

cities &lt;- cities %&gt;%
  left_join(original_text %&gt;%
                unnest_tokens(word, text) %&gt;%
                filter(word %in% tolower(cities$cityName)) %&gt;%
                count(word, sort = TRUE) %&gt;%
                rename(cityName = word),
            
            by = &#39;cityName&#39;)

cities$n &lt;- replace_na(cities$n, 0)</code></pre>
<pre class="r"><code>cities &lt;- cities %&gt;%
  select(cityName, latitude, longitude, n) %&gt;%
  rename(Occurance_In_Text = n) %&gt;%
  arrange(desc(Occurance_In_Text))

#cities to plot
cities_in_text &lt;- cities %&gt;%
  filter(Occurance_In_Text &gt; 0) </code></pre>
<p>We can create a data structure to understand the co occurance of these cities with words like “to” and “from” in each line. It can give us a <strong>naive</strong> estimate of goods and services coming in and out. “to” stands for import, “from” stands for export, summation of “in”+“at” stands for inventory.</p>
<div id="trading-power-export-inventory---import" class="section level4">
<h4>Trading Power = <strong>EXPORT</strong> + <strong>INVENTORY</strong> - <strong>IMPORT</strong></h4>
<pre class="r"><code>pointer &lt;- c(&quot;to&quot;, &quot;from&quot;, &quot;in&quot;, &quot;at&quot;)

for(j in 1:length(pointer)) {

      for(i in 1:length(cities_in_text$cityName)) {
            
                cities_in_text[i, pointer[j]] &lt;- nrow(txt[grep(
                      
                                str_c(pointer[j], &#39; &#39;, cities_in_text$cityName[i]), 
                                                     
                                txt$text), ])}
}


cities_in_text &lt;- cities_in_text %&gt;%
                    mutate(import = to,
                           export = from,
                           inventory = `in` + at,
                           trade_power = export + inventory - import) %&gt;%
                    select(cityName, Occurance_In_Text, trade_power, latitude, longitude) %&gt;%
                    arrange(desc(trade_power))

cities_in_text %&gt;%
  select(cityName, Occurance_In_Text, trade_power) %&gt;%
  head() %&gt;%
  pander::pander()</code></pre>
<table style="width:62%;">
<colgroup>
<col width="16%" />
<col width="27%" />
<col width="18%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">cityName</th>
<th align="center">Occurance_In_Text</th>
<th align="center">trade_power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">kanesh</td>
<td align="center">87</td>
<td align="center">34</td>
</tr>
<tr class="even">
<td align="center">hahhum</td>
<td align="center">15</td>
<td align="center">8</td>
</tr>
<tr class="odd">
<td align="center">wahsusana</td>
<td align="center">31</td>
<td align="center">7</td>
</tr>
<tr class="even">
<td align="center">zalpa</td>
<td align="center">7</td>
<td align="center">7</td>
</tr>
<tr class="odd">
<td align="center">durhumit</td>
<td align="center">27</td>
<td align="center">6</td>
</tr>
<tr class="even">
<td align="center">tuhpiya</td>
<td align="center">10</td>
<td align="center">5</td>
</tr>
</tbody>
</table>
<pre class="r"><code>library(ggmap)
library(ggthemes)

#setup map borders and select your map style
lat &lt;- cities$latitude
long &lt;- cities$longitude
bbox &lt;- make_bbox(long,lat,f=0.5)
b &lt;- get_map(bbox,maptype=&quot;watercolor&quot;,source=&quot;google&quot;)

#plot the cities mentioned in the text
ggmap(b) + geom_point(data = cities_in_text, 
           aes(longitude, latitude, size=trade_power),alpha=0.2, show.legend = F) +
           scale_size_continuous(range = c(2, 20)) +
  
           labs(x = &quot;Longitude&quot;, y = &quot;Latitude&quot;,
           title=&quot;Cities and their Trading Power&quot;, color = &quot;Type&quot;) +
  
           geom_text(data = cities_in_text, aes(longitude, latitude, label = cityName), 
                     check_overlap = TRUE) + 
theme_gdocs()</code></pre>
<p><img src="final_files/figure-html/unnamed-chunk-15-1.png" width="768" /></p>
<p>You are looking at the Asia Minor, Mezzopotamia, the Middle East, Greece and the southeast Mediterrenean Sea. The largest islands you see are the island of Crete and Cyprus.</p>
<p>The city of Kanesh is our biggest hub. Probably a capital city. And our famous Pusuken family have lived here.</p>
<p>The people who wrote these tablets had access to the sea ports in the south. So we are talking about some complicated trade network here. Probably Pharaohs of ancient Egypt, Phonecians and Mycenaeans are all playing a role at some point.</p>
<p><b>2018.03.11 </b></p>
<p>We know the most frequent words in these documents. How about the most important ones? We can try tfidf here.</p>
<pre class="r"><code>oare_words &lt;- txt %&gt;%
  unnest_tokens(word, text) %&gt;%
  count(title, word, sort = TRUE) %&gt;%
  ungroup()

total_words &lt;- oare_words %&gt;% 
  group_by(title) %&gt;% 
  summarize(total = sum(n))

oare_words &lt;- left_join(oare_words, total_words, by = &#39;title&#39;)</code></pre>
<pre class="r"><code>oare_stop_words &lt;- data.frame(word = c(&quot;gkt&quot;, &quot;sec&quot;, &quot;oaa&quot;, &quot;ca&quot;, &quot;g&quot;), lexicon = &#39;oare&#39;)

oare_words &lt;- oare_words %&gt;%
  anti_join(oare_stop_words) %&gt;%
  bind_tf_idf(word, title, n)

oare_words %&gt;%
  select(-total) %&gt;%
  arrange(desc(tf_idf)) %&gt;%
  head(10) %&gt;%
  select(title, word, n, tf_idf)</code></pre>
<pre class="r"><code>oare_words %&gt;%
  arrange(desc(tf_idf)) %&gt;%
  mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% 
  #group_by(title) %&gt;% 
  top_n(5) %&gt;% 
  #ungroup %&gt;%
  ggplot(aes(word, tf_idf, fill = title)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = &quot;tf-idf&quot;) +
  #facet_wrap(~title, ncol = 2, scales = &quot;free&quot;) +
  coord_flip() + theme_gray()</code></pre>
<p><img src="final_files/figure-html/unnamed-chunk-18-1.png" width="576" /></p>
<p>tf-idf algorithm decreases the weight for commonly used words and increases the weight for words that are not used very much.</p>
<p>We had ruling family names in the word frequency plot. They were the <strong>Pusuken, Assurnada and Assurmalik</strong> families.</p>
<p>Now we have some other names being reported in tfidf plots. And by far, the most significant names are <strong>Kuliya and Aliabum</strong>. These names are more important then the powerful families according to the algorithm. They are also more important then gold, silver and the trade items. Maybe they are not mentioned that much. But they seem to play some significant role. This is really curious. Who are these people?</p>
<pre class="r"><code>head(original_text[str_detect(original_text$text, &quot;Kuliya&quot;), 1], 15)[4, ] %&gt;%
  pander::pander()</code></pre>
<table style="width:44%;">
<colgroup>
<col width="44%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Whoever has brought in loaded donkeys via the narrow track in order to do business over there, even when he is a resident of a karum, make him pay 3 shekels of silver per mina and let Kuliya personally bring it here.</td>
</tr>
</tbody>
</table>
<p>Kuliya is a servant of Pusuken family. He delivers messages, goods and payments. He is Kuliya, son of Aliabum. Loyal servant of the sons of Pusuken. He takes the caravans from Kanesh and brings to the city of Ulama in the south. There he gives the cargo to the representatives of Sea People. Aliabum is his father. They call him Kuliya, son of Aliabum. This trade network can not function without him.</p>
</div>
</div>
<div id="an-unsual-autopsy-of-ancient-trade-records" class="section level3">
<h3>An unsual autopsy of ancient trade records</h3>
<pre class="r"><code>library(tidyr)
library(igraph)
library(ggraph)

#create bigram
oare_bigrams &lt;- txt %&gt;%
  unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2)

#separate them
bigrams_separated &lt;- oare_bigrams %&gt;%
  separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;)

#filter out stopwords
bigrams_filtered &lt;- bigrams_separated %&gt;%
  filter(!word1 %in% stop_words$word) %&gt;%
  filter(!word2 %in% stop_words$word) 

#bigram counts:
bigram_counts &lt;- bigrams_filtered %&gt;% 
  count(word1, word2, sort = TRUE)

#create a graph
bigram_graph &lt;- bigram_counts %&gt;%
  filter(n &gt; 30) %&gt;%
  graph_from_data_frame()

#plot the graph

a &lt;- grid::arrow(type = &quot;closed&quot;, length = unit(.15, &quot;inches&quot;))
set.seed(2016)
ggraph(bigram_graph, layout = &quot;fr&quot;) +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, &#39;inches&#39;)) +
  geom_node_point(color = &quot;lightblue&quot;, size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()</code></pre>
<p><img src="final_files/figure-html/unnamed-chunk-20-1.png" width="960" /></p>
<p><em>Kuliya wakes up early morning with the sound of black &gt;&gt; donkeys. They are on the way to Ulama.</em></p>
<p><em>The main cargo is 300 kutanum &gt;&gt; textiles. It worths more than 10 talents &gt;&gt; and 50 minas &gt;&gt; of silver according to the tablet he is carrying with him. The letter starts with Dear &gt;&gt; brothers again. He doesn’t understand why sons of Pusuken call these bastards brother all the time.</em></p>
<p><em>Transport &gt;&gt; tariff is 60 shekels &gt;&gt; of silver. They will report it to the colony &gt;&gt; office in Ulama when they arrive, with approved delivery notice. He will deliver a huge profit to the family to clear all the claims &gt;&gt; outstanding</em></p>
<p>This network plot is quite informative. We see the monatery system around the <strong>silver</strong> and the order of scale for measurement. Talent is the biggest and probably a <strong>refined silver</strong> is the most valuable. Shekels should be like cents. Shekel - Minas - Silver is the strongest triangle of payment. Textile measurements are in kutanum. Strong presence of <strong>colony office</strong> is indicating a regulating superpower, most probably the Empire.</p>
<pre class="r"><code>money &lt;- data.frame(word = c(&quot;tin&quot;, &quot;minas&quot;, &quot;talent&quot;, &quot;talents&quot;, &quot;shekels&quot;, &quot;mina&quot;, &quot;refined&quot;, &quot;silver&quot;))</code></pre>
<p><b>2018.03.13 </b></p>
<p>How do these letters feel like? Mostly <strong>positive</strong> or <strong>negative</strong> language? And which words are contributing most to these sentiments?</p>
<p>I am going to use a special lexicon built for modern financial analysis. This is a kind of lexicon which you can expect to see in an analysis of stock market trading.</p>
<p>I am curious how it can perform on 4000 year old commercial records.</p>
<pre class="r"><code>library(gridExtra)
#first get the tidy format
tidy_oare &lt;- txt %&gt;%
  group_by(title) %&gt;%
  ungroup() %&gt;%
  unnest_tokens(word, text) %&gt;%
  #remove silver and gold because they dont give sentiment here
  anti_join(data.frame(word = c(&#39;silver&#39;, &#39;gold&#39;))) %&gt;% 
  anti_join(stop_words) %&gt;%
  mutate(linenumber = row_number())
  

#build afinn bing and nrc lexicon sentiments
afinn &lt;- tidy_oare %&gt;% 
  inner_join(get_sentiments(&quot;afinn&quot;)) %&gt;% 
  group_by(index = linenumber %/% 150) %&gt;% 
  summarise(sentiment = sum(score)) %&gt;% 
  mutate(method = &quot;AFINN&quot;)

bing_and_nrc &lt;- bind_rows(tidy_oare %&gt;% 
                            inner_join(get_sentiments(&quot;bing&quot;)) %&gt;%
                            mutate(method = &quot;Bing et al.&quot;),
                          tidy_oare %&gt;% 
                            inner_join(get_sentiments(&quot;nrc&quot;) %&gt;% 
                                         filter(sentiment %in% c(&quot;positive&quot;, 
                                                                 &quot;negative&quot;))) %&gt;%
                            mutate(method = &quot;NRC&quot;)) %&gt;%
  count(method, index = linenumber %/% 150, sentiment) %&gt;%
  spread(sentiment, n, fill = 0) %&gt;%
  mutate(sentiment = positive - negative)

#plot the sentiments together
p1 &lt;- bind_rows(afinn, 
                bing_and_nrc) %&gt;%
        ggplot(aes(index, sentiment, fill = method)) +
        geom_col(show.legend = FALSE) +
        facet_wrap(~method, ncol = 1, scales = &quot;free_y&quot;) + 
        theme_fivethirtyeight() 
        


p2 &lt;- tidy_oare %&gt;%
        count(word) %&gt;%
        inner_join(get_sentiments(&quot;loughran&quot;), by = &quot;word&quot;) %&gt;%
        filter(sentiment %in% c(&quot;positive&quot;, 
                                &quot;negative&quot;,
                                &quot;constrining&quot;,
                                &quot;uncertainty&quot;)) %&gt;% 
        group_by(sentiment) %&gt;%
        top_n(5, n) %&gt;%
        ungroup() %&gt;%
        mutate(word = reorder(word, n)) %&gt;%
        ggplot(aes(word, n)) +
        geom_col() +
        coord_flip() +
        facet_wrap(~ sentiment, scales = &quot;free&quot;) + theme_fivethirtyeight() +
        theme(axis.text.x=element_blank()) + scale_fill_brewer(palette=&quot;Set3&quot;) 

grid.arrange(p1, p2, ncol = 2)</code></pre>
<p><img src="final_files/figure-html/unnamed-chunk-22-1.png" width="864" /></p>
<p>We see that we have quite many positive sentiment as well as negatives. And the financial analysis lexicon is giving accurate matches. For example seizing someone because of his debts.</p>
<p>xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
