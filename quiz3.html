<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}

.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Cagdas Yetkin</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="quiz.html">Quiz</a>
</li>
<li>
  <a href="final.html">Final Project</a>
</li>
<li>
  <a href="software.html">Programming</a>
</li>
<li>
  <a href="teaching.html">Teaching</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="contact.html">
    <span class="fa fa-envelope fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="http://github.com/cagdasyetkin">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/cagdasyetkin">
    <span class="fa fa-twitter fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/cagdasyetkin/">
    <span class="fa fa-linkedin fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<hr />
<hr />
<p><b> Submitted 2018.25.02 </b></p>
<ol style="list-style-type: decimal">
<li>In your own words describe LDA</li>
</ol>
<p>When we are dealing with collection of documents, such as all the text files from Bronze Age Assyrian civilization, we may want to divide them into natural groups like “Trade” and “Warfare”.</p>
<p>LDA is a popular method for fitting such models: (a) It considers each document as a mixture of topics (b) And each topic as a mixture of words.</p>
<p>What does this mean?</p>
<p>Lets say we have a 2 topic LDA model on ancient Assyrian texts. The first text script has a probability of 85% coming from topic 1, and a probability of 15% coming from topic 2 (a).</p>
<p>In “Warfare” and “Trade” example above, the most frequent words in “warfare” topic can be: [“massacre”, “head”, “enslave”, “burn”], while “Trade” topic may contain: [“amphora”, “cargo”, “pay”, “ship”] (b).</p>
<p>LDA is a method estimating both of these (a and b) at the same time. It is important to realize that this is an unsuperwise method. We dont have these “Trade” and “Warfare” labels at the beginning. And the analyst decides how many topics there will be.</p>
<ol start="2" style="list-style-type: decimal">
<li>In your own words, describe the process of a full tidy text analysis</li>
</ol>
<p>Start with getting the data and preprocessing it %&gt;% We unnest_tokens and create a tidy text format %&gt;% Now we can do summaries, count the words, compute frequencies and tf-idf %&gt;% It is time to visualize these first results.</p>
<p>Start sentiment analysis, decide/find the lexicons you want to use %&gt;% inner_join them with your tidy text %&gt;% group_by and do summaries %&gt;% visualize these second group of findings.</p>
<p>Start again with your raw data %&gt;% this time unnest_tokens using ngram %&gt;% do filtering where needed and then apply tf-idf %&gt;% visualize your findings %&gt;% apply sentiment analysis on your ngram %&gt;% visualize your findings</p>
<p>Create document term matrix from the text %&gt;% apply LDA to do topic modeling %&gt;% work on your topics using dplyr tidyr as usual %&gt;% visualize your findings.</p>
<p>During visualization look at other libraries other than ggplot also, such as igraph.</p>
<ol start="3" style="list-style-type: decimal">
<li>Do a short tidy text analysis where you extract topics, explain why they are good or bad.</li>
</ol>
<pre class="r"><code>library(stringr)
library(dplyr)
library(tidyr)
library(tidytext)
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(scales)
library(broom)
library(purrr)
library(topicmodels)
library(tm)
library(SnowballC) #stem</code></pre>
<p>We will load 2 books from Game of Thrones series, The Lord of the Rings series and The Hobbit. Our objective is to do topic modeling where we expect finding natural groups of items.</p>
<p>The underlying philosophy is to be able to use this method even when we are not sure what we are looking for.</p>
<p>In this setup below we already know that we have 2 author and thus, 2 natural groups. This can get confusing and useless if we try to extract 4-5 topics out of them.</p>
<pre class="r"><code>GoT2 &lt;- readLines(&quot;GoT2.txt&quot;) %&gt;%
  data_frame() %&gt;%
  mutate(title = &quot;A Clash of Kings&quot;) 

GoT3 &lt;- readLines(&quot;GoT3.txt&quot;) %&gt;%
  data_frame() %&gt;%
  mutate(title = &quot;A Storm of Swords&quot;)

lotr &lt;- readLines(&quot;lotr.txt&quot;) %&gt;%
  data_frame() %&gt;%
  mutate(title = &quot;Lord of the Rings&quot;)

hobbit &lt;- readLines(&quot;hobbit.txt&quot;) %&gt;%
  data_frame() %&gt;%
  mutate(title = &quot;The Hobbit&quot;)


books &lt;- bind_rows(list(GoT2, GoT3, lotr, hobbit)) 
colnames(books) &lt;- c(&quot;text&quot;, &quot;title&quot;)

my_stop_words &lt;- data_frame(word = c(&#39;page&#39;))</code></pre>
<pre class="r"><code># divide into documents, each representing one chapter
by_chapter &lt;- books %&gt;%
  group_by(title) %&gt;%
  mutate(chapter = cumsum(str_detect(text, regex(&quot;^chapter &quot;, ignore_case = TRUE)))) %&gt;%
  ungroup() %&gt;%
  filter(chapter &gt; 0) %&gt;%
  unite(document, title, chapter)</code></pre>
<pre class="r"><code># split into words
by_chapter_word &lt;- by_chapter %&gt;%
  unnest_tokens(word, text)

# find document-word counts
word_counts &lt;- by_chapter_word %&gt;%
  anti_join(stop_words) %&gt;%
  anti_join(my_stop_words) %&gt;%
  count(document, word, sort = TRUE) %&gt;%
  ungroup()

word_counts</code></pre>
<pre><code>## # A tibble: 239,860 x 3
##    document             word       n
##    &lt;chr&gt;                &lt;chr&gt;  &lt;int&gt;
##  1 A Storm of Swords_80 ser      226
##  2 A Storm of Swords_80 lord     210
##  3 A Storm of Swords_80 son      146
##  4 A Clash of Kings_68  ser      143
##  5 Lord of the Rings_1  frodo    140
##  6 A Clash of Kings_68  lord     129
##  7 Lord of the Rings_1  bilbo    121
##  8 Lord of the Rings_39 pippin   105
##  9 Lord of the Rings_49 sam      105
## 10 A Storm of Swords_80 lady     104
## # ... with 239,850 more rows</code></pre>
<p>‘ser’ means ‘sir’ in the world of Game of Thrones</p>
<pre class="r"><code>chapters_dtm &lt;- word_counts %&gt;%
  cast_dtm(document, word, n)

chapters_dtm</code></pre>
<pre><code>## &lt;&lt;DocumentTermMatrix (documents: 224, terms: 23982)&gt;&gt;
## Non-/sparse entries: 239860/5132108
## Sparsity           : 96%
## Maximal term length: 32
## Weighting          : term frequency (tf)</code></pre>
<pre class="r"><code>chapters_lda &lt;- LDA(chapters_dtm, k = 2, control = list(seed = 1234))
chapters_lda</code></pre>
<pre><code>## A LDA_VEM topic model with 2 topics.</code></pre>
<pre class="r"><code>chapter_topics &lt;- tidy(chapters_lda, matrix = &quot;beta&quot;)
chapter_topics</code></pre>
<pre><code>## # A tibble: 47,964 x 3
##    topic term                                           beta
##    &lt;int&gt; &lt;chr&gt;                                         &lt;dbl&gt;
##  1     1 ser   0.0000000000000882                           
##  2     2 ser   0.00923                                      
##  3     1 lord  0.00217                                      
##  4     2 lord  0.0115                                       
##  5     1 son   0.00103                                      
##  6     2 son   0.00251                                      
##  7     1 frodo 0.00976                                      
##  8     2 frodo 0.0000000000000000000000000000000000000000190
##  9     1 bilbo 0.00415                                      
## 10     2 bilbo 0.0000000000000000000000000000000000000653   
## # ... with 47,954 more rows</code></pre>
<pre class="r"><code>top_terms &lt;- chapter_topics %&gt;%
  group_by(topic) %&gt;%
  top_n(5, beta) %&gt;%
  ungroup() %&gt;%
  arrange(topic, -beta)

top_terms</code></pre>
<pre><code>## # A tibble: 10 x 3
##    topic term       beta
##    &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;
##  1     1 frodo   0.00976
##  2     1 sam     0.00697
##  3     1 gandalf 0.00660
##  4     1 dark    0.00500
##  5     1 time    0.00477
##  6     2 lord    0.0115 
##  7     2 ser     0.00923
##  8     2 tyrion  0.00455
##  9     2 king    0.00448
## 10     2 jon     0.00436</code></pre>
<pre class="r"><code>top_terms %&gt;%
  mutate(term = reorder(term, beta)) %&gt;%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = &quot;free&quot;) +
  coord_flip()</code></pre>
<p><img src="quiz3_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>It is amazing. The algorithm was able to classify The Lord of the Rings and The Game of Thrones almost perfectly. This is nice. However, I have set the k = 2. I knew that there were 2 novels. If that information is not available to us, it would be hard to evaluate and understand. It can also be misleading.</p>
<p>Each document in this analysis represented a single chapter. Thus, we may want to know which topics are associated with each chapter. Can we put the books back together?</p>
<p>per-document-per-topic probabilities : γ(“gamma”)</p>
<pre class="r"><code>chapters_gamma &lt;- tidy(chapters_lda, matrix = &quot;gamma&quot;)
chapters_gamma</code></pre>
<pre><code>## # A tibble: 448 x 3
##    document             topic      gamma
##    &lt;chr&gt;                &lt;int&gt;      &lt;dbl&gt;
##  1 A Storm of Swords_80     1 0.00000533
##  2 A Clash of Kings_68      1 0.00000953
##  3 Lord of the Rings_1      1 1.000     
##  4 Lord of the Rings_39     1 1.000     
##  5 Lord of the Rings_49     1 1.000     
##  6 A Storm of Swords_67     1 0.0000236 
##  7 A Storm of Swords_19     1 0.0000176 
##  8 Lord of the Rings_2      1 1.000     
##  9 Lord of the Rings_10     1 1.000     
## 10 Lord of the Rings_7      1 1.000     
## # ... with 438 more rows</code></pre>
<p>Each gamma you see here is estimated proportion of words from that chapter that are generated from that topic. For example, we estimate that each word in the Storm of Swords Chapter 80 has only 0.000532% probability of coming from topic 1 (which is actually The Lord of The Rings).</p>
<pre class="r"><code>chapters_gamma &lt;- chapters_gamma %&gt;%
  separate(document, c(&quot;title&quot;, &quot;chapter&quot;), sep = &quot;_&quot;, convert = TRUE)

chapters_gamma</code></pre>
<pre><code>## # A tibble: 448 x 4
##    title             chapter topic      gamma
##    &lt;chr&gt;               &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;
##  1 A Storm of Swords      80     1 0.00000533
##  2 A Clash of Kings       68     1 0.00000953
##  3 Lord of the Rings       1     1 1.000     
##  4 Lord of the Rings      39     1 1.000     
##  5 Lord of the Rings      49     1 1.000     
##  6 A Storm of Swords      67     1 0.0000236 
##  7 A Storm of Swords      19     1 0.0000176 
##  8 Lord of the Rings       2     1 1.000     
##  9 Lord of the Rings      10     1 1.000     
## 10 Lord of the Rings       7     1 1.000     
## # ... with 438 more rows</code></pre>
<pre class="r"><code># reorder titles in order of topic 1, topic 2, etc before plotting
chapters_gamma %&gt;%
  mutate(title = reorder(title, gamma * topic)) %&gt;%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ title)</code></pre>
<p><img src="quiz3_files/figure-html/unnamed-chunk-12-1.png" width="672" /> We notice that almost all of the chapters from The Lord of The Rings and The Game of Thrones series were uniquely identified as a single topic each.</p>
<p>Are there any cases where the topic most associated with a chapter belonged to another <strong>autor</strong>?</p>
<pre class="r"><code>chapter_classifications &lt;- chapters_gamma %&gt;%
  group_by(title, chapter) %&gt;%
  top_n(1, gamma) %&gt;%
  ungroup()

chapter_classifications</code></pre>
<pre><code>## # A tibble: 224 x 4
##    title             chapter topic gamma
##    &lt;chr&gt;               &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
##  1 Lord of the Rings       1     1 1.000
##  2 Lord of the Rings      39     1 1.000
##  3 Lord of the Rings      49     1 1.000
##  4 Lord of the Rings       2     1 1.000
##  5 Lord of the Rings      10     1 1.000
##  6 Lord of the Rings       7     1 1.000
##  7 The Hobbit              5     1 1.000
##  8 Lord of the Rings      22     1 1.000
##  9 Lord of the Rings      21     1 1.000
## 10 Lord of the Rings      51     1 1.000
## # ... with 214 more rows</code></pre>
<p>Find the misclassified chapters</p>
<pre class="r"><code>book_topics &lt;- chapter_classifications %&gt;%
  count(title, topic) %&gt;%
  group_by(title) %&gt;%
  top_n(1, n) %&gt;%
  ungroup() %&gt;%
  transmute(consensus = title, topic)

chapter_classifications %&gt;%
  inner_join(book_topics, by = &quot;topic&quot;) %&gt;%
  filter(title != consensus)</code></pre>
<pre><code>## # A tibble: 224 x 5
##    title             chapter topic gamma consensus        
##    &lt;chr&gt;               &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;            
##  1 Lord of the Rings       1     1 1.000 The Hobbit       
##  2 Lord of the Rings      39     1 1.000 The Hobbit       
##  3 Lord of the Rings      49     1 1.000 The Hobbit       
##  4 Lord of the Rings       2     1 1.000 The Hobbit       
##  5 Lord of the Rings      10     1 1.000 The Hobbit       
##  6 Lord of the Rings       7     1 1.000 The Hobbit       
##  7 The Hobbit              5     1 1.000 Lord of the Rings
##  8 Lord of the Rings      22     1 1.000 The Hobbit       
##  9 Lord of the Rings      21     1 1.000 The Hobbit       
## 10 Lord of the Rings      51     1 1.000 The Hobbit       
## # ... with 214 more rows</code></pre>
<p>It turns out there is chapter misclassification only within the same autor. Otherwise, we classified the autors perfectly.</p>
<p>LDA can be a good approach when we have a huge collection of unlabeled texts and we are trying to make sense of it. However, we should not forget that we are setting up how many topics will be generated ourselves.</p>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
